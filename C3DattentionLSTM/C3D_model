
import numpy

train_d = numpy.load('train_data.npy')
train_d = train_d.transpose((0,2,3,4,1))
train_l = numpy.load('train_label.npy')
train_l = train_d.transpose((0,2,3,4,1))
test_d = numpy.load('test_data.npy')
test_d = train_d.transpose((0,2,3,4,1))
test_l = numpy.load('test_label.npy')
test_l = train_d.transpose((0,2,3,4,1))


def save_history(history):
    loss = history.history['loss']
    acc = history.history['acc']
    val_loss = history.history['val_loss']
    val_acc = history.history['val_acc']
    nb_epoch = len(acc)

    with open('result.txt', 'w') as fp:
        fp.write('epoch\tloss\tacc\tval_loss\tval_acc\n')
        for i in range(nb_epoch):
            fp.write('{}\t{}\t{}\t{}\t{}\n'.format(
                i, loss[i], acc[i], val_loss[i], val_acc[i]))
#---------------------------------------------3DCNN model---------------------------------------------------------------
from keras.models import Sequential
from keras.layers import Dense, Flatten
from keras.models import Sequential

from keras.layers.convolutional import Convolution3D, MaxPooling3D
# Define model
model = Sequential()
from numpy import array
input_shape=(16, 112, 112, 3) # l, h, w, c
#input_shape=(3, 16, 112, 112) # c, l, h, w

model.add(Convolution3D(64, 3, 3, 3, activation='relu', border_mode='same', name='conv1', input_shape=input_shape))
model.add(MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2), border_mode='valid', name='pool1'))
model.add(Dropout(0.5))

# 2nd layer group

model.add(Convolution3D(128, 3, 3, 3, activation='relu', border_mode='same', name='conv2'))
model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), border_mode='valid', name='pool2'))
model.add(Dropout(0.5))

# 3rd layer group

model.add(Convolution3D(256, 3, 3, 3, activation='relu', border_mode='same', name='conv3a'))
model.add(Convolution3D(256, 3, 3, 3, activation='relu', border_mode='same', name='conv3b'))
model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), border_mode='valid', name='pool3'))
model.add(Dropout(0.5))

# 4th layer group

model.add(Convolution3D(512, 3, 3, 3, activation='relu', border_mode='same', name='conv4a'))
model.add(Convolution3D(512, 3, 3, 3, activation='relu',border_mode='same', name='conv4b'))
model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), border_mode='valid', name='pool4'))
model.add(Dropout(0.5))

# 5th layer group

model.add(Convolution3D(512, 3, 3, 3, activation='relu', border_mode='same', name='conv5a'))
model.add(Convolution3D(512, 3, 3, 3, activation='relu', border_mode='same', name='conv5b'))
model.add(MaxPooling3D(pool_size=(2, 1, 1), strides=(2, 1, 1), border_mode='valid', name='pool5'))
model.add(Dropout(0.5))

model.add(Flatten())
model.compile(loss='categorical_crossentropy',optimizer='adam', metrics=['accuracy'])
model.summary()

#----------------------------------------------------------Load parameter-------------------------------------------------------
'''
import caffe_pb2 as caffe

import numpy as np



p = caffe.NetParameter()

p.ParseFromString(

    open('conv3d_deepnetA_sport1m_iter_1900000', 'rb').read()

)



def rot90(W):

    for i in range(W.shape[0]):

        for j in range(W.shape[1]):

            for k in range(W.shape[2]):

                W[i, j, k] = np.rot90(W[i, j, k], 2)

    return W



params = []

conv_layers_indx = [1, 4, 7, 9, 12, 14, 17, 19]

#fc_layers_indx = [22, 25, 28]



for i in conv_layers_indx:

    layer = p.layers[i]

    weights_b = np.array(layer.blobs[1].data, dtype=np.float32)

    weights_p = np.array(layer.blobs[0].data, dtype=np.float32).reshape(

        layer.blobs[0].num, layer.blobs[0].channels, layer.blobs[0].length,

        layer.blobs[0].height, layer.blobs[0].width

    )

    weights_p = np.transpose(weights_p, (2, 3, 4, 1, 0))

    weights_p = rot90(weights_p)

    params.append([weights_p, weights_b])





model_layers_indx = [0, 2, 4, 5, 7, 8, 10, 11]  

for i, j in zip(model_layers_indx, range(11)):

    model.layers[i].set_weights(params[j])



import h5py



model.save_weights('sports1M_weights.h5', overwrite=True)

json_string = model.to_json()

with open('sports1M_model.json', 'w') as f:

    f.write(json_string)
'''
#------------------------------------------------------Loading UCF11 data--------------------------------------------------------------------------
history = model.fit(train_d, train_l, validation_data=(test_d, test_l), batch_size=130,epochs=100, verbose=1, shuffle=True)
plot_history(history)
save_history(history)
#model.evaluate(test_d, test_l, verbose=1)
model_json = model.to_json()
   
with open( 'ucf101_3dcnnmodel.json', 'w') as json_file:
    json_file.write(model_json)
model.save_weights( 'ucf101_3dcnnmodel.hd5')

loss, acc = model.evaluate(test_d, test_l, verbose=1)
print('Test loss:', loss)
print('Test accuracy:', acc)
'''
#-------------------------------------------------------Load data-------------------------------------------------------------------------

from keras import applications
from keras.optimizers import SGD
from sklearn.utils import shuffle
from keras.preprocessing.image import ImageDataGenerator
from keras.callbacks import EarlyStopping, ModelCheckpoint
from keras.applications.vgg16 import VGG16
from keras.layers import LSTM
import numpy as np
import glob,os
from scipy.misc import imread,imresize

batch_size = 128

def bring_data_from_directory():
  datagen = ImageDataGenerator(rescale=1. / 255)
  train_generator = datagen.flow_from_directory(
          'train',
          target_size=(224, 224),
          batch_size=batch_size,
          class_mode='categorical',  # this means our generator will only yield batches of data, no labels
          shuffle=True,
          classes=['class_1','class_2','class_3','class_4','class_5'])

  validation_generator = datagen.flow_from_directory(
          'validate',
          target_size=(224, 224),
          batch_size=batch_size,
          class_mode='categorical',  # this means our generator will only yield batches of data, no labels
          shuffle=True,
          classes=['class_1','class_2','class_3','class_4','class_5'])
  return train_generator,validation_generator
  
def load_C3D_model():
  from keras.models import model_from_json

  base_model = model_from_json(open('sports1M_model.json', 'r').read())

  base_model.load_weights('sports1M_weights.h5')
  
  print("Model loaded..!")
  print(base_model.summary())
  

  #test set
  x_generator = None
  y_lable = None
  batch = 0
  for x,y in train_generator:
      if batch == (56021/batch_size):
          break
      print("predict on batch:",batch)
      batch+=1
      if x_generator==None:
         x_generator = base_model.predict_on_batch(x)
         y_lable = y
         print(y)
      else:
         x_generator = np.append(x_generator,base_model.predict_on_batch(x),axis=0)
         y_lable = np.append(y_lable,y,axis=0)
  x_generator,y_lable = shuffle(x_generator,y_lable)
  np.save(open('video_x_VGG16.npy', 'w'),x_generator)
  np.save(open('video_y_VGG16.npy','w'),y_lable)
  
  #validate
  batch = 0
  x_generator = None
  y_lable = None
  for x,y in validation_generator:
      if batch == (3974/batch_size):
          break
      print("predict on batch validate:",batch)
      batch+=1
      if x_generator==None:
         x_generator = base_model.predict_on_batch(x)
         y_lable = y
      else:
         x_generator = np.append(x_generator,base_model.predict_on_batch(x),axis=0)
         y_lable = np.append(y_lable,y,axis=0)
  x_generator,y_lable = shuffle(x_generator,y_lable)
  np.save(open('video_x_validate_VGG16.npy', 'w'),x_generator)
  np.save(open('video_y_validate_VGG16.npy','w'),y_lable)
  
train_generator,validation_generator = bring_data_from_directory()  
load_C3D_model()
'''
