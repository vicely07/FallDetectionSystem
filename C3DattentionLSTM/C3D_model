

#---------------------------------------------model---------------------------------------------------------------
from keras.models import Sequential
from keras.layers import Dense
from keras.layers.advanced_activations import LeakyReLU
from keras.losses import categorical_crossentropy
from keras.models import Sequential
from keras.optimizers import Adam
from keras.utils import np_utils
from keras.utils.vis_utils import plot_model
from sklearn.model_selection import train_test_split
from keras.utils.vis_utils import plot_model
from keras.layers.convolutional import Convolution3D, MaxPooling3D
# Define model
model = Sequential()
from numpy import array
input_shape=(20, 16, 112, 112, 3) # l, h, w, c

model.add(Convolution3D(64, 3, 3, 3, activation='relu', border_mode='same', name='conv1'), input_shape=input_shape)
model.add(MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2), border_mode='valid', name='pool1'))

# 2nd layer group

model.add(Convolution3D(128, 3, 3, 3, activation='relu', border_mode='same', name='conv2'))
model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), border_mode='valid', name='pool2'))

# 3rd layer group

model.add(Convolution3D(256, 3, 3, 3, activation='relu', border_mode='same', name='conv3a'))
model.add(Convolution3D(256, 3, 3, 3, activation='relu', border_mode='same', name='conv3b'))
model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), border_mode='valid', name='pool3'))

# 4th layer group

model.add(Convolution3D(512, 3, 3, 3, activation='relu', border_mode='same', name='conv4a'))
model.add(Convolution3D(512, 3, 3, 3, activation='relu',border_mode='same', name='conv4b'))
model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), border_mode='valid', name='pool4'))

# 5th layer group

model.add(Convolution3D(512, 3, 3, 3, activation='relu', border_mode='same', name='conv5a'))
model.add(Convolution3D(512, 3, 3, 3, activation='relu', border_mode='same', name='conv5b'))
model.add(MaxPooling3D(pool_size=(2, 1, 1), strides=(2, 1, 1), border_mode='valid', name='pool5'))




