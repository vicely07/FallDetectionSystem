

#---------------------------------------------3DCNN model---------------------------------------------------------------
from keras.models import Sequential
from keras.layers import Dense
from keras.models import Sequential

from keras.layers.convolutional import Convolution3D, MaxPooling3D
# Define model
model = Sequential()
from numpy import array
input_shape=(16, 112, 112, 3) # l, h, w, c

model.add(Convolution3D(64, 3, 3, 3, activation='relu', border_mode='same', name='conv1', input_shape=input_shape))
model.add(MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2), border_mode='valid', name='pool1'))

# 2nd layer group

model.add(Convolution3D(128, 3, 3, 3, activation='relu', border_mode='same', name='conv2'))
model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), border_mode='valid', name='pool2'))

# 3rd layer group

model.add(Convolution3D(256, 3, 3, 3, activation='relu', border_mode='same', name='conv3a'))
model.add(Convolution3D(256, 3, 3, 3, activation='relu', border_mode='same', name='conv3b'))
model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), border_mode='valid', name='pool3'))

# 4th layer group

model.add(Convolution3D(512, 3, 3, 3, activation='relu', border_mode='same', name='conv4a'))
model.add(Convolution3D(512, 3, 3, 3, activation='relu',border_mode='same', name='conv4b'))
model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), border_mode='valid', name='pool4'))

# 5th layer group

model.add(Convolution3D(512, 3, 3, 3, activation='relu', border_mode='same', name='conv5a'))
model.add(Convolution3D(512, 3, 3, 3, activation='relu', border_mode='same', name='conv5b'))
model.add(MaxPooling3D(pool_size=(2, 1, 1), strides=(2, 1, 1), border_mode='valid', name='pool5'))
#----------------------------------------------------------Load parameter-------------------------------------------------------

import caffe_pb2 as caffe

import numpy as np



p = caffe.NetParameter()

p.ParseFromString(

    open('conv3d_deepnetA_sport1m_iter_1900000', 'rb').read()

)



def rot90(W):

    for i in range(W.shape[0]):

        for j in range(W.shape[1]):

            for k in range(W.shape[2]):

                W[i, j, k] = np.rot90(W[i, j, k], 2)

    return W



params = []

conv_layers_indx = [1, 4, 7, 9, 12, 14, 17, 19]

#fc_layers_indx = [22, 25, 28]



for i in conv_layers_indx:

    layer = p.layers[i]

    weights_b = np.array(layer.blobs[1].data, dtype=np.float32)

    weights_p = np.array(layer.blobs[0].data, dtype=np.float32).reshape(

        layer.blobs[0].num, layer.blobs[0].channels, layer.blobs[0].length,

        layer.blobs[0].height, layer.blobs[0].width

    )

    weights_p = np.transpose(weights_p, (2, 3, 4, 1, 0))

    weights_p = rot90(weights_p)

    params.append([weights_p, weights_b])





model_layers_indx = [0, 2, 4, 5, 7, 8, 10, 11]  

for i, j in zip(model_layers_indx, range(11)):

    model.layers[i].set_weights(params[j])



import h5py



model.save_weights('sports1M_weights.h5', overwrite=True)

json_string = model.to_json()

with open('sports1M_model.json', 'w') as f:

    f.write(json_string)

#-------------------------------------------------------Test-------------------------------------------------------------------------



from keras.models import model_from_json

#------------------------------------------------Attention LSTM layer---------------------------------------------------------

model = model_from_json(open('sports1M_model.json', 'r').read())

C3DSport1Model = model.load_weights('sports1M_weights.h5')

#-------------------------------------Attention Layer-----------------------------------------------------------------------------
from keras import backend as K
from keras.engine import InputSpec
from keras.layers import LSTM, activations, Wrapper, Recurrent, recurrent

class AttentionLSTM(Wrapper):
    """
    This wrapper will provide an attention layer to a recurrent layer. 
     
    # Arguments:
        layer: `Recurrent` instance with consume_less='gpu' or 'mem'
     
    # Examples:
     
    ```python
    model = Sequential()
    model.add(LSTM(10, return_sequences=True), batch_input_shape=(4, 5, 10))
    model.add(TFAttentionRNNWrapper(LSTM(10, return_sequences=True, consume_less='gpu')))
    model.add(Dense(5))
    model.add(Activation('softmax'))
    model.compile(loss='categorical_crossentropy', optimizer='rmsprop') 
    ```
     
    # References
    - [Grammar as a Foreign Language](https://arxiv.org/abs/1412.7449)
     
     
    """
    def __init__(self, layer, **kwargs):
        assert isinstance(layer, Recurrent)
        if layer.get_config()['consume_less']=='cpu':
            raise Exception("AttentionLSTMWrapper doesn't support RNN's with consume_less='cpu'")
        self.supports_masking = True
        super(AttentionLSTM, self).__init__(layer, **kwargs)
 
    def build(self, input_shape):
        assert len(input_shape) >= 3
        self.input_spec = [InputSpec(shape=input_shape)]
        nb_samples, nb_time, input_dim = input_shape
 
        if not self.layer.built:
            self.layer.build(input_shape)
            self.layer.built = True
 
        super(AttentionLSTM, self).build()
         
        self.W1 = self.layer.init((input_dim, input_dim, 1, 1), name='{}_W1'.format(self.name))
        self.W2 = self.layer.init((self.layer.output_dim, input_dim), name='{}_W2'.format(self.name))
        self.b2 = K.zeros((input_dim,), name='{}_b2'.format(self.name))
        self.W3 = self.layer.init((input_dim*2, input_dim), name='{}_W3'.format(self.name))
        self.b3 = K.zeros((input_dim,), name='{}_b3'.format(self.name))
        self.V = self.layer.init((input_dim,), name='{}_V'.format(self.name))
 
        self.trainable_weights = [self.W1, self.W2, self.W3, self.V, self.b2, self.b3]
 
    def get_output_shape_for(self, input_shape):
        return self.layer.get_output_shape_for(input_shape)
 
    def step(self, x, states):
        # This is based on [tensorflows implementation](https://github.com/tensorflow/tensorflow/blob/c8a45a8e236776bed1d14fd71f3b6755bd63cc58/tensorflow/python/ops/seq2seq.py#L506).
        # First, we calculate new attention masks:
        #   attn = softmax(V^T * tanh(W2 * X +b2 + W1 * h))
        # and we make the input as a concatenation of the input and weighted inputs which is then
        # transformed back to the shape x of using W3
        #   x = W3*(x+X*attn)+b3
        # Then, we run the cell on a combination of the input and previous attention masks:
        #   h, state = cell(x, h).
         
        nb_samples, nb_time, input_dim = self.input_spec[0].shape
        h = states[0]
        X = states[-1]
        xW1 = states[-2]
         
        Xr = K.reshape(X,(-1,nb_time,1,input_dim))
        hW2 = K.dot(h,self.W2)+self.b2
        hW2 = K.reshape(hW2,(-1,1,1,input_dim)) 
        u = K.tanh(xW1+hW2)
        a = K.sum(self.V*u,[2,3])
        a = K.softmax(a)
        a = K.reshape(a,(-1, nb_time, 1, 1))
         
        # Weight attention vector by attention
        Xa = K.sum(a*Xr,[1,2])
        Xa = K.reshape(Xa,(-1,input_dim))
         
        # Merge input and attention weighted inputs into one vector of the right size.
        x = K.dot(K.concatenate([x,Xa],1),self.W3)+self.b3    
         
        h, new_states = self.layer.step(x, states)
        return h, new_states
 
    def get_constants(self, x):
        constants = self.layer.get_constants(x)
         
        # Calculate K.dot(x, W2) only once per sequence by making it a constant
        nb_samples, nb_time, input_dim = self.input_spec[0].shape
        Xr = K.reshape(x,(-1,nb_time,input_dim,1))
        Xrt = K.permute_dimensions(Xr, (0, 2, 1, 3))
        xW1t = K.conv2d(Xrt,self.W1,border_mode='same')     
        xW1 = K.permute_dimensions(xW1t, (0, 2, 3, 1))
        constants.append(xW1)
         
        # we need to supply the full sequence of inputs to step (as the attention_vector)
        constants.append(x)
         
        return constants
 
    def call(self, x, mask=None):
        # input shape: (nb_samples, time (padded with zeros), input_dim)
        input_shape = self.input_spec[0].shape
        if K._BACKEND == 'tensorflow':
            if not input_shape[1]:
                raise Exception('When using TensorFlow, you should define '
                                'explicitly the number of timesteps of '
                                'your sequences.\n'
                                'If your first layer is an Embedding, '
                                'make sure to pass it an "input_length" '
                                'argument. Otherwise, make sure '
                                'the first layer has '
                                'an "input_shape" or "batch_input_shape" '
                                'argument, including the time axis. '
                                'Found input shape at layer ' + self.name +
                                ': ' + str(input_shape))
 
        if self.layer.stateful:
            initial_states = self.layer.states
        else:
            initial_states = self.layer.get_initial_states(x)
        constants = self.get_constants(x)
        preprocessed_input = self.layer.preprocess_input(x)
         
 
        last_output, outputs, states = K.rnn(self.step, preprocessed_input,
                                             initial_states,
                                             go_backwards=self.layer.go_backwards,
                                             mask=mask,
                                             constants=constants,
                                             unroll=self.layer.unroll,
                                             input_length=input_shape[1])
        if self.layer.stateful:
            self.updates = []
            for i in range(len(states)):
                self.updates.append((self.layer.states[i], states[i]))
 
        if self.layer.return_sequences:
            return outputs
        else:
            return last_output
#----------------------------------------Building data input functions----------------------------------------------------------
from keras.models import Sequential
from keras.layers import Dropout, Flatten, Dense
from keras import applications
from keras.optimizers import SGD
from sklearn.utils import shuffle
from keras.preprocessing.image import ImageDataGenerator
from keras.callbacks import EarlyStopping, ModelCheckpoint
from keras.applications.vgg16 import VGG16
from keras.layers import LSTM
import numpy as np
import glob,os
from scipy.misc import imread,imresize

batch_size = 128

def bring_data_from_directory():
  datagen = ImageDataGenerator(rescale=1. / 255)
  train_generator = datagen.flow_from_directory(
          'train',
          target_size=(224, 224),
          batch_size=batch_size,
          class_mode='categorical',  # this means our generator will only yield batches of data, no labels
          shuffle=True,
          classes=['class_1','class_2','class_3','class_4','class_5'])

  validation_generator = datagen.flow_from_directory(
          'validate',
          target_size=(224, 224),
          batch_size=batch_size,
          class_mode='categorical',  # this means our generator will only yield batches of data, no labels
          shuffle=True,
          classes=['class_1','class_2','class_3','class_4','class_5'])
  return train_generator,validation_generator

def load_C3D_model():
  base_model = C3DSport1Model
  print("Model loaded..!")
  print(base_model.summary())
  return(base_model)

def extract_features_and_store(train_generator,validation_generator,base_model):

  train_data = np.load(open('train_data.npy'))
  train_labels = np.load(open('train_label.npy'))
  train_data,train_labels = shuffle(train_data,train_labels)
  validation_data = np.load(open('test_data.npy'))
  validation_labels = np.load(open('test_label.npy'))
  validation_data,validation_labels = shuffle(validation_data,validation_labels)

  train_data = train_data.reshape(train_data.shape[0],
                     train_data.shape[1] * train_data.shape[2],
                     train_data.shape[3])
  validation_data = validation_data.reshape(validation_data.shape[0],
                     validation_data.shape[1] * validation_data.shape[2],
                     validation_data.shape[3])
  
  return train_data,train_labels,validation_data,validation_labels

def train_model(train_data,train_labels,validation_data,validation_labels):
  ''' used fully connected layers, SGD optimizer and 
      checkpoint to store the best weights'''

  model = Sequential()
  model.add(AttentionLSTM(LSTM(24,dropout=0.2,input_shape=(train_data.shape[1],
                     train_data.shape[2]), consume_less='gpu')))
  model.add(Dense(11, activation='softmax'))
  sgd = SGD(lr=0.003, decay = 1e-6, momentum=0.2, nesterov=True)
  model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])
  #model.load_weights('video_1_LSTM_1_512.h5')
  callbacks = [ EarlyStopping(monitor='val_loss', patience=10, verbose=0), ModelCheckpoint('video_1_LSTM_1_1024.h5', monitor='val_loss', save_best_only=True, verbose=0) ]
  nb_epoch = 500
  model.fit(train_data,train_labels,validation_data=(validation_data,validation_labels),batch_size=batch_size,nb_epoch=nb_epoch,callbacks=callbacks,shuffle=True,verbose=1)
  
  loss, acc = model.evaluate(test_d, test_l, verbose=1)

  return print('Test loss:', loss)

  return print('Test accuracy:', acc)
  #return model


if __name__ == '__main__':
  train_generator,validation_generator = bring_data_from_directory()
  base_model = load_C3D_model()
  train_data,train_labels,validation_data,validation_labels = extract_features_and_store(train_generator,validation_generator,base_model)
  train_model(train_data,train_labels,validation_data,validation_labels)
  
  #test_on_whole_videos(train_data,train_labels,validation_data,validation_labels)
