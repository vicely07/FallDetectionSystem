from keras import backend as K, initializers, regularizers, constraints

from keras.engine.topology import Layer





def dot_product(x, kernel):

    """

    Wrapper for dot product operation, in order to be compatible with both

    Theano and Tensorflow

    Args:

        x (): input

        kernel (): weights

    Returns:

    """

    if K.backend() == 'tensorflow':

        # todo: check that this is correct

        return K.squeeze(K.dot(x, K.expand_dims(kernel)), axis=-1)

    else:

        return K.dot(x, kernel)





class Attention(Layer):

    def __init__(self,

                 W_regularizer=None, b_regularizer=None,

                 W_constraint=None, b_constraint=None,

                 bias=True,

                 return_attention=False,

                 **kwargs):

        """

        Keras Layer that implements an Attention mechanism for temporal data.

        Supports Masking.

        Follows the work of Raffel et al. [https://arxiv.org/abs/1512.08756]

        # Input shape

            3D tensor with shape: `(samples, steps, features)`.

        # Output shape

            2D tensor with shape: `(samples, features)`.

        :param kwargs:

        Just put it on top of an RNN Layer (GRU/LSTM/SimpleRNN) with return_sequences=True.

        The dimensions are inferred based on the output shape of the RNN.





        Note: The layer has been tested with Keras 1.x



        Example:

        

            # 1

            model.add(LSTM(64, return_sequences=True))

            model.add(Attention())

            # next add a Dense layer (for classification/regression) or whatever...



            # 2 - Get the attention scores

            hidden = LSTM(64, return_sequences=True)(words)

            sentence, word_scores = Attention(return_attention=True)(hidden)



        """

        self.supports_masking = True

        self.return_attention = return_attention

        self.init = initializers.get('glorot_uniform')



        self.W_regularizer = regularizers.get(W_regularizer)

        self.b_regularizer = regularizers.get(b_regularizer)



        self.W_constraint = constraints.get(W_constraint)

        self.b_constraint = constraints.get(b_constraint)



        self.bias = bias

        super(Attention, self).__init__(**kwargs)



    def build(self, input_shape):

        assert len(input_shape) == 3



        self.W = self.add_weight((input_shape[-1],),

                                 initializer=self.init,

                                 name='{}_W'.format(self.name),

                                 regularizer=self.W_regularizer,

                                 constraint=self.W_constraint)

        if self.bias:

            self.b = self.add_weight((input_shape[1],),

                                     initializer='zero',

                                     name='{}_b'.format(self.name),

                                     regularizer=self.b_regularizer,

                                     constraint=self.b_constraint)

        else:

            self.b = None



        self.built = True



    def compute_mask(self, input, input_mask=None):

        # do not pass the mask to the next layers

        return None



    def call(self, x, mask=None):

        eij = dot_product(x, self.W)



        if self.bias:

            eij += self.b



        eij = K.tanh(eij)



        a = K.exp(eij)



        # apply mask after the exp. will be re-normalized next

        if mask is not None:

            # Cast the mask to floatX to avoid float64 upcasting in theano

            a *= K.cast(mask, K.floatx())



        # in some cases especially in the early stages of training the sum may be almost zero

        # and this results in NaN's. A workaround is to add a very small positive number Îµ to the sum.

        # a /= K.cast(K.sum(a, axis=1, keepdims=True), K.floatx())

        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())



        weighted_input = x * K.expand_dims(a)



        result = K.sum(weighted_input, axis=1)



        if self.return_attention:

            return [result, a]

        return result



    def compute_output_shape(self, input_shape):

        if self.return_attention:

            return [(input_shape[0], input_shape[-1]),

                    (input_shape[0], input_shape[1])]

        else:

            return input_shape[0], input_shape[-1]

#---------------------------------------3d CNN model--------------------------------------------------------------
from keras.models import Sequential

from keras.utils import multi_gpu_model

from keras.layers import Dense, TimeDistributed, Flatten, Dropout, LSTM, Activation

from keras.layers.convolutional import Convolution3D, MaxPooling3D

from keras import optimizers

import numpy as np

# Define model

model = Sequential()

from numpy import array

input_shape=(1, 16, 112, 112, 3) # l, h, w, c



model.add(TimeDistributed(Convolution3D(64, 3, 3, 3, activation='relu', border_mode='same', name='conv1'), input_shape=input_shape))

model.add(TimeDistributed(MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2), border_mode='valid', name='pool1')))

#model.add(TimeDistributed(Dropout(0.5)))


# 2nd layer group



model.add(TimeDistributed(Convolution3D(128, 3, 3, 3, activation='relu', border_mode='same', name='conv2')))

model.add(TimeDistributed(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), border_mode='valid', name='pool2')))

#model.add(TimeDistributed(Dropout(0.5)))


# 3rd layer group



model.add(TimeDistributed(Convolution3D(256, 3, 3, 3, activation='relu', border_mode='same', name='conv3a')))

model.add(TimeDistributed(Convolution3D(256, 3, 3, 3, activation='relu', border_mode='same', name='conv3b')))

model.add(TimeDistributed(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), border_mode='valid', name='pool3')))

#model.add(TimeDistributed(Dropout(0.5)))

# 4th layer group



model.add(TimeDistributed(Convolution3D(512, 3, 3, 3, activation='relu', border_mode='same', name='conv4a')))

model.add(TimeDistributed(Convolution3D(512, 3, 3, 3, activation='relu',border_mode='same', name='conv4b')))

model.add(TimeDistributed(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), border_mode='valid', name='pool4')))

#model.add(TimeDistributed(Dropout(0.5)))

# 5th layer group



model.add(TimeDistributed(Convolution3D(512, 3, 3, 3, activation='relu', border_mode='same', name='conv5a')))

model.add(TimeDistributed(Convolution3D(512, 3, 3, 3, activation='relu', border_mode='same', name='conv5b')))

model.add(TimeDistributed(MaxPooling3D(pool_size=(2, 1, 1), strides=(2, 1, 1), border_mode='valid', name='pool5')))

model.add(TimeDistributed(Flatten()))
model.add(TimeDistributed(LSTM(units=24, return_sequences=False)))
model.add(Attention())
model.add(Dropout(0.5))
model.add(Dense(512, activation='relu'))
model.add(Activation('softmax'))
model.summary()

#----------------------------------------------------------Load parameter-------------------------------------------------------
import caffe_pb2 as caffe
import numpy as np

p = caffe.NetParameter()
p.ParseFromString(
    open('conv3d_deepnetA_sport1m_iter_1900000', 'rb').read()
)

def rot90(W):
    for i in range(W.shape[0]):
        for j in range(W.shape[1]):
            for k in range(W.shape[2]):
                W[i, j, k] = np.rot90(W[i, j, k], 2)
    return W

params = []
conv_layers_indx = [1, 4, 7, 9, 12, 14, 17, 19]

for i in conv_layers_indx:
    layer = p.layers[i]
    weights_b = np.array(layer.blobs[1].data, dtype=np.float32)
    weights_p = np.array(layer.blobs[0].data, dtype=np.float32).reshape(
        layer.blobs[0].num, layer.blobs[0].channels, layer.blobs[0].length,
        layer.blobs[0].height, layer.blobs[0].width
    )
    weights_p = np.transpose(weights_p, (2, 3, 4, 1, 0))
    weights_p = rot90(weights_p)
    params.append([weights_p, weights_b])


model_layers_indx = [0, 2, 4, 5, 7, 8, 10, 11]  
for i, j in zip(model_layers_indx, range(11)):
    model.layers[i].set_weights(params[j])

import h5py

model.save_weights('sports1M_weights.h5', overwrite=True)
json_string = model.to_json()
with open('sports1M_model.json', 'w') as f:
    f.write(json_string)
#-------------------------------------------------------Test-------------------------------------------------------------------------

from keras.models import model_from_json
#------------------------------------------------Add Attention LSTM layer---------------------------------------------------------

model = model_from_json(open('sports1M_model.json', 'r').read())
model.load_weights('sports1M_weights.h5')
model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])

model.summary()

#-------------------------------------------------------------Test set--------------------------------------------------------------------
with open('labels.txt', 'r') as f:
    labels = [line.strip() for line in f.readlines()]
print('Total labels: {}'.format(len(labels)))


import cv2
import numpy as np

cap = cv2.VideoCapture('dM06AMFLsrc.mp4')

vid = []
while True:
    ret, img = cap.read()
    if not ret:
        break
    vid.append(cv2.resize(img, (171, 128)))
vid = np.array(vid, dtype=np.float32)

X = (vid[2000:2016, 8:120, 30:142, :].transpose((3, 0, 1, 2)))
X = np.array([X])
print(X[0].shape)
print(X.shape)
#output = np.append([1], X.shape)
#output = np.append([-1], output)

#output = X[0].reshape((-1, 1, 16, 112, 112, 3))
#print(output.shape[0])

output = X.reshape((-1, 1, 16, 112, 112, 3))
print(output.shape)
print(output[0].shape)
output = model.predict_on_batch(output)


print('Position of maximum probability: {}'.format(output[0].argmax()))

print('Corresponding label: {}'.format(labels[output[0].argmax()]))
print('Maximum probability:', max(output[0]))
print('Maximum probability:', max(output[0][0]))
print('Maximum probability: {:.5f}'.format(max(output[0][0])))
