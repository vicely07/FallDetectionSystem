
#------------------------------------------lstm attention model-------------------------------------------------------
from keras.layers import merge

from keras.layers.core import *

from keras.layers.recurrent import LSTM

from keras.models import *



INPUT_DIM = 2

TIME_STEPS = 20

# if True, the attention vector is shared across the input_dimensions where the attention is applied.

SINGLE_ATTENTION_VECTOR = False

APPLY_ATTENTION_BEFORE_LSTM = False





def attention_3d_block(inputs):

    # inputs.shape = (batch_size, time_steps, input_dim)

    input_dim = int(inputs.shape[2])

    a = Permute((2, 1))(inputs)

    a = Reshape((input_dim, TIME_STEPS))(a) # this line is not useful. It's just to know which dimension is what.

    a = Dense(TIME_STEPS, activation='softmax')(a)

    if SINGLE_ATTENTION_VECTOR:

        a = Lambda(lambda x: K.mean(x, axis=1), name='dim_reduction')(a)

        a = RepeatVector(input_dim)(a)

    a_probs = Permute((2, 1), name='attention_vec')(a)

    output_attention_mul = merge([inputs, a_probs], name='attention_mul', mode='mul')

    return output_attention_mul


def model_attention_applied_before_lstm():

    inputs = input(shape=(TIME_STEPS, INPUT_DIM,))

    attention_mul = attention_3d_block(inputs)

    lstm_units = 24

    attention_mul = LSTM(lstm_units, return_sequences=False)(attention_mul)

    output = Dense(1, activation='sigmoid')(attention_mul)

    model = Model(input=[inputs], output=output)

    return model


#---------------------------------------------model---------------------------------------------------------------

from keras.models import model_from_json

model = model_from_json(open('sports1M_model.json', 'r').read())

model.load_weights('sports1M_weights.h5')

model.compile(loss='mean_squared_error', optimizer='sgd')
model.add(attention_3d_block(model.output_shape))
model.add(model_attention_applied_before_lstm())
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
model.add(Dropout(0.5))
model.add(Dense(11, activation='softmax'))

print(model.summary())



